Story: Wyckoff Research Harness v0 — CSV Inspection Outputs

ID: WYCKOFF-R2
Type: Research / Usability
Depends on: WYCKOFF-R1 (baseline benchmark complete)
Location: docs/research/wyckoff_algo
Goal: Make research outputs human-inspectable without altering logic

⸻

Objective

Augment the existing Wyckoff research harness to emit CSV inspection artifacts alongside Parquet outputs, enabling easy review in Excel, Numbers, or charting tools.

This story is purely additive:
	•	No algorithm changes
	•	No benchmark math changes
	•	No filters or tuning
	•	No DB writes

The goal is to see what we already trust, not change it.

⸻

Non-Goals (Explicit)
	•	No refactoring of legacy detector
	•	No changes to event definitions
	•	No changes to benchmark calculations
	•	No new indicators or signals
	•	No production pipeline impact

⸻

Scope of Changes

Files Allowed to Change

Only the following files may be modified:

docs/research/wyckoff_algo/
├── runner/
│   └── run_detector.py
├── benchmark/
│   └── run_bench.py

No other files should be touched.

⸻

STEP 1 — CSV Output for Events (Chart Inspection)

Modify: runner/run_detector.py

Current behavior (unchanged):
	•	Writes:

outputs/events.parquet



New additive behavior:
	•	Also write:

outputs/events.csv



Required CSV schema (exact)

symbol
event
direction
role
event_date
bar_index
impl

This CSV must:
	•	Be a 1:1 mirror of events.parquet
	•	Be sorted by:

symbol, event_date


	•	Contain no derived or extra columns

Purpose

This file is intended for:
	•	Opening in Excel / Numbers
	•	Copy-pasting dates into TradingView
	•	Verifying events against price charts

⸻

STEP 2 — Chart-Friendly Event Timeline CSV

New file (derived from same data)

Also emit:

outputs/events_timeline.csv

Required schema

symbol
event_date
event
direction
role

Rules:
	•	One row per event
	•	No bar_index
	•	No impl column
	•	Sorted by:

symbol, event_date



Purpose

This file is optimized for:
	•	Visual chart inspection
	•	Lightweight joins with OHLCV exports
	•	Manual sanity checks

This file must be generated from the same in-memory event DataFrame used for Parquet, not recomputed.

⸻

STEP 3 — CSV Output for Benchmark Summary

Modify: benchmark/run_bench.py

Current behavior (unchanged):
	•	Writes:

outputs/benchmark_results.parquet



New additive behavior:
	•	Also write:

outputs/benchmark_results.csv



CSV schema

The CSV must exactly mirror the Parquet schema, including:

event
direction
role
horizon
impl
mean_return
mae_mean
signal_count

Sorting:

event, horizon


⸻

Acceptance Criteria (All Must Pass)
	•	Parquet outputs remain unchanged
	•	CSV outputs are additive only
	•	events.csv rows == events.parquet rows
	•	events_timeline.csv contains symbol + dates suitable for charting
	•	benchmark_results.csv matches Parquet content exactly
	•	No algorithm logic modified
	•	No benchmark math modified
	•	Re-running produces identical CSV and Parquet outputs

⸻