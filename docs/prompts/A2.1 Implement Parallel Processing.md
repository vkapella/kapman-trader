You are acting as the execution engineer for the KapMan MVP.

Context:
- A2 Local TA + Price Metrics job is correct, deterministic, and chunked (A2.1).
- Current runtime: ~21 minutes for ~10,200 tickers (single process).
- Chunking yields ~10–15% improvement but is insufficient for production.
- Hardware: Apple M1 (10 cores).
- Workload is CPU-bound pandas/ta computations.

Goal:
Implement A2.2 — Parallel Chunked Execution.

Hard Constraints:
- Deterministic results (bit-for-bit identical JSON blobs)
- No schema changes
- No indicator surface changes
- No async / threading
- Multiprocessing only
- Explicit process boundaries
- Safe DB writes (no race conditions)

Required Changes:

1. Add CLI flags:
   --workers N (default: auto)
   --max-workers N (hard cap, default: 6)

2. Execution model:
   - Split ticker universe into chunks (reuse A2.1 logic)
   - Distribute chunks across a multiprocessing.Pool
   - Each worker:
     - Processes whole chunks
     - Opens its own DB connection
     - Writes snapshots idempotently

3. Determinism:
   - Chunk assignment order must be stable
   - Results must not depend on worker count
   - INSERT ... ON CONFLICT semantics preserved

4. Instrumentation:
   - Log per-worker:
     - chunks completed
     - tickers/sec
   - Log global:
     - total runtime
     - speedup vs single-process baseline
     - effective throughput

5. Safety:
   - Default workers = min(4, cpu_count-2)
   - Respect --workers override
   - Clean shutdown on KeyboardInterrupt

6. Tests:
   - Unit: worker chunk partitioning
   - Integration (skipped unless env var set):
     - workers=1 vs workers=4 produce identical snapshots

Deliverables:
- Updated core/metrics/a2_local_ta_job.py
- Updated scripts/run_a2_local_ta.py
- Tests passing under pytest
- Clear log header summarizing worker configuration

Do not add parallelism anywhere else.
Do not refactor unrelated code.