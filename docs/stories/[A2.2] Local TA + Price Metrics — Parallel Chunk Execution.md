# [A2.2] Local TA + Price Metrics — Parallel Chunk Execution

Issue Type: Performance Scaling
Depends On: A2.1 (Chunked Execution)

--------------------------------------------------------------------
OBJECTIVE
--------------------------------------------------------------------

Reduce A2 runtime from ~18–20 minutes/day to <5 minutes/day by introducing
controlled parallel execution across independent ticker chunks.

This story builds directly on A2.1’s chunking foundation.

--------------------------------------------------------------------
SCOPE (STRICT)
--------------------------------------------------------------------

IN SCOPE:
• Parallel execution of ticker chunks
• Configurable worker count
• Deterministic results identical to A2/A2.1
• Explicit CPU-bound scaling only

OUT OF SCOPE:
• Indicator logic changes
• Schema changes
• GPU usage
• Distributed execution
• Adaptive scheduling
• Cross-date parallelism

--------------------------------------------------------------------
EXECUTION MODEL
--------------------------------------------------------------------

• Chunking remains identical to A2.1
• Each chunk is an independent unit of work
• Parallelism applies ONLY to chunk execution

Preferred model:
• multiprocessing.Pool or concurrent.futures.ProcessPoolExecutor
• One chunk per worker
• Worker count configurable

Proposed flags:
• --ticker-chunk-size N (existing)
• --workers M (new)

Default:
• workers = min(physical_cores - 1, 8)

--------------------------------------------------------------------
DETERMINISM & SAFETY
--------------------------------------------------------------------

• Each worker:
  – Computes indicators locally
  – Writes via idempotent upsert
• Order of execution MUST NOT affect outputs
• Logs may be interleaved; data must not differ

--------------------------------------------------------------------
EXPECTED PERFORMANCE
--------------------------------------------------------------------

Based on current metrics:
• ~0.10 sec / ticker
• ~10,200 tickers
• ~21 min single-process

Projected:
• 4 workers → ~6–7 minutes
• 8 workers → ~3–4 minutes
• Diminishing returns beyond CPU saturation

--------------------------------------------------------------------
RISKS
--------------------------------------------------------------------

• DB connection pool exhaustion
• Excessive process startup overhead
• Log readability
• OS-level resource contention

Mitigations:
• Bounded worker pool
• Chunk size ≥250
• Explicit connection lifecycle per worker

--------------------------------------------------------------------
SUCCESS CRITERIA
--------------------------------------------------------------------

• ≥60% runtime reduction vs A2.1
• Identical snapshot outputs
• Stable memory usage
• Clean shutdown on failure
• Clear telemetry per worker

--------------------------------------------------------------------
FOLLOW-ON
--------------------------------------------------------------------

• A2.3 — Vectorized indicator paths
• A2.4 — Historical backfill parallelization
• A2.5 — Production scheduler integration