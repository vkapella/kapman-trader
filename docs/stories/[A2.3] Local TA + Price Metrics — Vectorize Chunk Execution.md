A2.3 — Vectorized Chunk Execution for Local TA + Price Metrics

Story ID: A2.3
Roadmap Ref: S-MET-03 (extension)
Predecessors: A2, A2.1 (chunking), A2.2 (multiprocessing)
Status: Planned
Owner: KapMan MVP

⸻

Phase 1 — Story Framing & Intent Validation

Why this issue exists

A2.2 demonstrated that multiprocessing yields near-linear speedup by parallelizing work across CPU cores. However, profiling shows that within each worker, the dominant cost remains Python-level per-ticker loops, repeatedly slicing OHLCV data and invoking indicator constructors one ticker at a time.

This story eliminates that inner-loop inefficiency by vectorizing indicator computation at the chunk level, allowing Pandas/NumPy to operate on wide DataFrames and compute each indicator once per chunk, not once per ticker.

This is the final single-host optimization step before any distributed or multi-node design.

⸻

What this issue explicitly delivers
	•	Vectorized computation of technical indicators and price metrics per chunk
	•	One OHLCV load per chunk (wide DataFrame)
	•	One computation pass per indicator category per chunk
	•	Extraction of latest-row values per ticker into deterministic JSON
	•	Preservation of:
	•	Existing chunking semantics
	•	Existing multiprocessing model
	•	Existing DB write and idempotency behavior

⸻

What this issue explicitly does NOT do
	•	No distributed execution
	•	No new persistence schema
	•	No new indicators or metric definitions
	•	No change to indicator surface or JSON contract
	•	No GPU acceleration
	•	No async/event-driven redesign

⸻

Phase 2 — Inputs, Outputs, and Invariants

Tables Read
	•	ohlcv
	•	Columns: ticker_id, date, open, high, low, close, volume
	•	Read for a fixed date window sufficient to satisfy max lookback (e.g. SMA200)

⸻

Tables Written
	•	daily_snapshots
	•	Columns written (unchanged):
	•	technical_indicators_json
	•	price_metrics_json
	•	model_version
	•	created_at

Writes remain:
	•	Deterministic
	•	Idempotent
	•	INSERT … ON CONFLICT (time, ticker_id) DO UPDATE

⸻

External Libraries
	•	pandas
	•	numpy
	•	ta (technical analysis library)

No new dependencies introduced.

⸻

Invariants & Constraints
	•	Indicator definitions come only from docs/reference/ta_indicator_surface.py
	•	All indicators must be emitted:
	•	Latest value only
	•	NULL if insufficient history or computation failure
	•	Output JSON shape must be identical to A2/A2.2
	•	Chunk boundaries must not affect results
	•	Ordering of tickers within a chunk must be deterministic

⸻

Phase 3 — Data Flow & Control Flow

High-Level Execution Flow

For each snapshot date:
	1.	Partition tickers into chunks (existing logic)
	2.	For each chunk (inside a worker):
	1.	Load OHLCV for all tickers in chunk into a single wide DataFrame
	2.	Pivot/group data so each ticker’s time series is aligned
	3.	For each indicator category:
	•	Compute the indicator once across the DataFrame
	•	Result is a DataFrame with time index × ticker columns
	4.	Select the last row only
	5.	Assemble per-ticker JSON blobs
	3.	Write results using existing idempotent upsert
	4.	Emit per-chunk timing + ETA updates

⸻

Key Implementation Details

OHLCV Loading
	•	Single SQL query per chunk
	•	Sorted by (ticker_id, date)
	•	Converted to Pandas DataFrame once

Indicator Computation
	•	Replace per-ticker loops with:
	•	Grouped / pivoted operations
	•	Vectorized Pandas + NumPy calls
	•	SMA variants (14/20/50/200) computed via rolling windows once

JSON Assembly
	•	Extract last-row values only
	•	Convert NaN → NULL deterministically
	•	Preserve existing JSON key order

⸻

Phase 4 — Failure Modes & Idempotency

Failure Modes
	•	Insufficient lookback for some tickers
	•	Division-by-zero or NaN propagation in vector ops
	•	Memory pressure for very large chunks

⸻

Handling Strategy
	•	All computation failures → NULL values (never abort job)
	•	Chunk-level try/except to isolate failures
	•	Memory bounded by chunk size (configurable)

⸻

Idempotency

Unchanged from A2/A2.2:
	•	Same inputs → same outputs
	•	Safe re-runs
	•	Partial progress is recoverable

⸻

Phase 5 — Testing Strategy

Unit Tests

Add tests under tests/unit/metrics/ to validate:
	•	Vectorized outputs match scalar A2 outputs for:
	•	RSI
	•	MACD
	•	SMA variants
	•	RVOL / VSI / HV
	•	JSON shape identical to pre-vectorized implementation
	•	Deterministic ordering across runs

⸻

Integration Tests

Extend existing A2 integration tests to:
	•	Run with vectorized path enabled
	•	Assert:
	•	Same snapshot counts
	•	Same indicator keys
	•	Acceptable numeric tolerance vs baseline

⸻

Test Constraints
	•	All tests must run via default pytest
	•	No new fixtures requiring external services
	•	No ad-hoc scripts

⸻

Phase 6 — Operational Considerations

Performance Expectations

Based on observed metrics:
	•	Single-process vectorization: ~1.5–2× speedup
	•	Combined with multiprocessing:
	•	Expected total speedup vs A2 baseline: 6–8×
	•	Primary limit becomes memory bandwidth, not Python overhead

⸻

Observability

Extend existing logging to include:
	•	Vectorized execution enabled/disabled
	•	Per-chunk compute time (vectorized vs overhead)
	•	Indicators/sec per worker

⸻

Reruns & Backfills
	•	Fully compatible with:
	•	Single-day runs
	•	Date ranges
	•	Backfills
	•	No behavior changes required downstream

⸻

Phase 7 — Final Notes

A2.3 completes single-host performance optimization for Local TA computation.

After this story:
	•	Remaining gains require:
	•	Distributed backfill
	•	Horizontal scaling
	•	Or precomputed indicator materialization

Those are explicitly out of scope here.

⸻

End of Story